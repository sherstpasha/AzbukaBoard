# -*- coding: utf-8 -*-
import os
import yaml
import pandas as pd
import argparse
import subprocess
import numpy as np
import matplotlib.pyplot as plt


def load_config(config_path):
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def run_get_metrics(submission_path, data_root, python_exe):
    try:
        cmd = [python_exe, 'get_metrics.py', '--submission', submission_path, '--data-root', data_root]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
        
        if result.returncode != 0:
            print(f"–û—à–∏–±–∫–∞: {submission_path}")
            if result.stderr:
                print(f"  –î–µ—Ç–∞–ª–∏: {result.stderr.strip()}")
            return {}
        
        metrics = {}
        lines = result.stdout.split('\n')
        in_results = False
        
        for line in lines:
            line = line.strip()
            if 'DATASET' in line and 'CER' in line and 'WER' in line:
                in_results = True
                continue
            if in_results and line.startswith('-' * 10):
                if metrics:
                    break
                continue
            if in_results and line and not line.startswith('='):
                parts = line.split()
                if len(parts) >= 4:
                    try:
                        dataset_name = parts[0]
                        cer = float(parts[1])
                        wer = float(parts[2])
                        accuracy = float(parts[3])
                        metrics[dataset_name] = {'cer': cer, 'wer': wer, 'accuracy': accuracy}
                    except (ValueError, IndexError):
                        continue
        return metrics
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return {}


def extract_dataset_and_model(filename, datasets):
    name = filename.replace('.csv', '')
    matched_dataset = None
    matched_length = 0
    
    for dataset_name in datasets.keys():
        if name.startswith(dataset_name + '_'):
            if len(dataset_name) > matched_length:
                matched_dataset = dataset_name
                matched_length = len(dataset_name)
    
    if matched_dataset:
        model_name = name[len(matched_dataset) + 1:]
        return matched_dataset, model_name
    return None, None


def collect_all_results(results_dir, data_root, datasets, python_exe):
    all_results = {dataset: {} for dataset in datasets.keys()}
    result_files = [f for f in os.listdir(results_dir) if f.endswith('.csv')]
    total_files = len(result_files)
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {total_files} —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
    
    for idx, filename in enumerate(result_files, 1):
        filepath = os.path.join(results_dir, filename)
        dataset_name, model_name = extract_dataset_and_model(filename, datasets)
        
        if not dataset_name or not model_name:
            continue
        
        print(f"[{idx}/{total_files}] {dataset_name} / {model_name}")
        metrics = run_get_metrics(filepath, data_root, python_exe)
        
        if dataset_name in metrics:
            all_results[dataset_name][model_name] = metrics[dataset_name]
            m = metrics[dataset_name]
            print(f"  CER={m['cer']:.4f}, WER={m['wer']:.4f}, ACC={m['accuracy']:.4f}")
    
    return all_results


def calculate_rankings(df):
    if 'CER' in df.columns:
        df['Rank_CER'] = df['CER'].rank(method='min', ascending=True)
    if 'WER' in df.columns:
        df['Rank_WER'] = df['WER'].rank(method='min', ascending=True)
    if 'Accuracy' in df.columns:
        df['Rank_Accuracy'] = df['Accuracy'].rank(method='min', ascending=False)
    
    rank_columns = [col for col in df.columns if col.startswith('Rank_')]
    if rank_columns:
        df['Average_Rank'] = df[rank_columns].mean(axis=1)
        df['Final_Rank'] = df['Average_Rank'].rank(method='min', ascending=True)
    
    return df


def create_ranking_table(dataset_name, results, output_dir):
    if not results:
        print(f"–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return None
    
    df = pd.DataFrame.from_dict(results, orient='index')
    df.index.name = 'Model'
    df = df.reset_index()
    df.rename(columns={'cer': 'CER', 'wer': 'WER', 'accuracy': 'Accuracy'}, inplace=True)
    
    df = calculate_rankings(df)
    
    if 'Average_Rank' in df.columns:
        df = df.sort_values('Average_Rank')
    
    output_columns = ['Final_Rank', 'Model', 'CER', 'WER', 'Accuracy', 'Average_Rank']
    output_columns = [col for col in output_columns if col in df.columns]
    df_output = df[output_columns].copy()
    
    for col in ['CER', 'WER', 'Accuracy', 'Average_Rank']:
        if col in df_output.columns:
            df_output[col] = df_output[col].round(4)
    
    if 'Final_Rank' in df_output.columns:
        df_output['Final_Rank'] = df_output['Final_Rank'].astype(int)
    
    output_path = os.path.join(output_dir, f"{dataset_name}_ranking.csv")
    df_output.to_csv(output_path, index=False, encoding='utf-8')
    
    print(f"\n{dataset_name}:")
    print(df_output.to_string(index=False))
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\n")
    
    return df_output


# ============================================================
# README GENERATION
# ============================================================

def generate_dataset_table(df, dataset_name, config):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown-—Ç–∞–±–ª–∏—Ü—É –¥–ª—è –æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞."""
    lines = []
    lines.append(f"## Dataset: {dataset_name}\n")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    ds_config = config.get('datasets', {}).get(dataset_name, {})
    if ds_config.get('homepage') and ds_config['homepage'] != '-':
        lines.append(f"**Homepage:** [{ds_config['homepage']}]({ds_config['homepage']})\n")
    if ds_config.get('author') and ds_config['author'] != '-':
        lines.append(f"**Author:** {ds_config['author']}\n")
    if ds_config.get('license') and ds_config['license'] != '-':
        lines.append(f"**License:** {ds_config['license']}\n")
    lines.append("")
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
    lines.append("| Rank | Model | CER ‚Üì | WER ‚Üì | ACC ‚Üë | Avg Rank |")
    lines.append("|------|-------|-------|-------|-------|----------|")
    
    for _, row in df.iterrows():
        rank = int(row['Final_Rank']) if 'Final_Rank' in row else '-'
        model = row['Model']
        cer = f"{row['CER']:.4f}" if 'CER' in row else '-'
        wer = f"{row['WER']:.4f}" if 'WER' in row else '-'
        acc = f"{row['Accuracy']:.4f}" if 'Accuracy' in row else '-'
        avg_rank = f"{row['Average_Rank']:.2f}" if 'Average_Rank' in row else '-'
        
        lines.append(f"| {rank} | {model} | {cer} | {wer} | {acc} | {avg_rank} |")
    
    lines.append("")
    return "\n".join(lines)


def generate_readme(rankings_dir, config, output_path="README.md", generate_charts=True):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π README.md —Ñ–∞–π–ª –∏–∑ ranking —Ç–∞–±–ª–∏—Ü."""
    
    # –°–Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    charts_dir = os.path.join(rankings_dir, "charts")
    if generate_charts:
        print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
        plot_radar_charts(rankings_dir, charts_dir)
    
    lines = []
    lines.append("# üèÜ AzbukaBoard ‚Äî Cyrillic Handwriting OCR Leaderboard\n")
    lines.append("Benchmark –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–æ–≥–æ —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –≤ –Ω–∞—á–∞–ª–µ
    if os.path.exists(charts_dir):
        lines.append("## üìä Comparison Charts\n")
        lines.append("### Accuracy Radar\n")
        lines.append("![Accuracy Radar](rankings/charts/radar_accuracy.png)\n")
        lines.append("### 1-CER Radar\n")
        lines.append("![1-CER Radar](rankings/charts/radar_1_cer.png)\n")
    
    lines.append("---\n")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ ranking —Ñ–∞–π–ª—ã
    ranking_files = [f for f in os.listdir(rankings_dir) if f.endswith('_ranking.csv')]
    
    # –ò—Å–∫–ª—é—á–∞–µ–º example –¥–∞—Ç–∞—Å–µ—Ç—ã
    ranking_files = [f for f in ranking_files if 'example' not in f.lower()]
    
    all_dfs = {}
    for filename in sorted(ranking_files):
        dataset_name = filename.replace('_ranking.csv', '')
        filepath = os.path.join(rankings_dir, filename)
        df = pd.read_csv(filepath)
        all_dfs[dataset_name] = df
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
        table = generate_dataset_table(df, dataset_name, config)
        lines.append(table)
        lines.append("---\n")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Ç—Ä–∏–∫–∞—Ö
    lines.append("## üìñ Metrics Description\n")
    lines.append("- **CER** (Character Error Rate) ‚Äî –î–æ–ª—è –æ—à–∏–±–æ—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤. –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ.\n")
    lines.append("- **WER** (Word Error Rate) ‚Äî –î–æ–ª—è –æ—à–∏–±–æ—á–Ω—ã—Ö —Å–ª–æ–≤. –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ.\n")
    lines.append("- **ACC** (Accuracy) ‚Äî –î–æ–ª—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫. –ß–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ.\n")
    lines.append("- **Avg Rank** ‚Äî –°—Ä–µ–¥–Ω–∏–π —Ä–∞–Ω–≥ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º.\n")
    lines.append("")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º README
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
    
    print(f"README –æ–±–Ω–æ–≤–ª—ë–Ω: {output_path}")
    return all_dfs


# ============================================================
# RADAR CHARTS
# ============================================================

def plot_radar_charts(rankings_dir, output_dir=None):
    """–°—Ç—Ä–æ–∏—Ç radar-–≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º."""
    
    if output_dir is None:
        output_dir = os.path.join(rankings_dir, "charts")
    os.makedirs(output_dir, exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ ranking —Ñ–∞–π–ª—ã
    ranking_files = [f for f in os.listdir(rankings_dir) if f.endswith('_ranking.csv')]
    ranking_files = [f for f in ranking_files if 'example' not in f.lower()]
    
    if not ranking_files:
        print("–ù–µ—Ç ranking —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")
        return
    
    dfs = {}
    for filename in ranking_files:
        dataset_name = filename.replace('_ranking.csv', '')
        # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
        short_name = dataset_name.replace('DonkeySmallOCR-Numbers-Printed-15random', 'DonkeyOCR')
        short_name = short_name.replace('YeniseiGovReports-', 'Yenisei-')
        short_name = short_name.replace('HandwrittenKazakhRussian', 'KZ-RU')
        short_name = short_name.replace('school_notebooks_RU', 'SchoolNB')
        short_name = short_name.replace('RussianSchoolEssays', 'Essays')
        short_name = short_name.replace('orig_cyrillic', 'OrigCyr')
        
        filepath = os.path.join(rankings_dir, filename)
        dfs[short_name] = pd.read_csv(filepath)
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤–æ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
    all_models = set(dfs[list(dfs.keys())[0]]['Model'].tolist())
    for df in dfs.values():
        all_models &= set(df['Model'].tolist())
    
    if not all_models:
        print("–ù–µ—Ç –º–æ–¥–µ–ª–µ–π, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤–æ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
        all_models = set()
        for df in dfs.values():
            all_models |= set(df['Model'].tolist())
    
    models = sorted(list(all_models))
    labels = list(dfs.keys())
    
    # –ì–µ–æ–º–µ—Ç—Ä–∏—è —Ä–∞–¥–∞—Ä–∞
    N = len(labels)
    angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()
    angles += angles[:1]
    
    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ 1 - CER
    EPS = 1e-3
    def safe_1_minus_cer(cer):
        val = 1.0 - cer
        return max(EPS, min(1.0, val))
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ä–∞–¥–∞—Ä–∞
    def plot_radar(metric, title, filename):
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))
        
        colors = plt.cm.tab20(np.linspace(0, 1, len(models)))
        
        for idx, model in enumerate(models):
            values = []
            valid = True
            
            for dataset in labels:
                df = dfs[dataset]
                model_row = df[df['Model'] == model]
                
                if model_row.empty:
                    valid = False
                    break
                
                row = model_row.iloc[0]
                
                if metric == "ACC":
                    values.append(row["Accuracy"])
                elif metric == "1-CER":
                    values.append(safe_1_minus_cer(row["CER"]))
            
            if not valid:
                continue
                
            values += values[:1]
            
            ax.plot(angles, values, linewidth=1.5, alpha=0.8, label=model, color=colors[idx])
            ax.fill(angles, values, alpha=0.1, color=colors[idx])
        
        ax.set_thetagrids(np.degrees(angles[:-1]), labels, fontsize=9)
        ax.set_ylim(0, 1)
        ax.set_title(title, pad=20, fontsize=14)
        
        ax.legend(loc='center left', bbox_to_anchor=(1.15, 0.5), frameon=False, fontsize=9)
        
        plt.tight_layout()
        output_path = os.path.join(output_dir, filename)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏
    plot_radar("ACC", "Accuracy (ACC) ‚Äî –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", "radar_accuracy.png")
    plot_radar("1-CER", "Quality (1 ‚àí CER) ‚Äî –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", "radar_1_cer.png")
    
    print(f"\n–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', default='config.yaml')
    parser.add_argument('--results-dir', default='results_ocr')
    parser.add_argument('--output-dir', default='rankings')
    parser.add_argument('--data-root', required=False, default=None)
    parser.add_argument('--python', default='python')
    parser.add_argument('--update-readme', action='store_true', help='–¢–æ–ª—å–∫–æ –æ–±–Ω–æ–≤–∏—Ç—å README –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö rankings')
    parser.add_argument('--charts', action='store_true', help='–¢–æ–ª—å–∫–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö rankings')
    parser.add_argument('--no-readme', action='store_true', help='–ù–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å README')
    parser.add_argument('--no-charts', action='store_true', help='–ù–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏')
    
    args = parser.parse_args()
    
    config = load_config(args.config)
    
    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ README
    if args.update_readme:
        generate_readme(args.output_dir, config)
        return
    
    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    if args.charts:
        plot_radar_charts(args.output_dir)
        return
    
    # –ü–æ–ª–Ω—ã–π —Ä–µ–∂–∏–º - –Ω—É–∂–µ–Ω data-root
    if args.data_root is None:
        print("–û—à–∏–±–∫–∞: --data-root –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --update-readme –∏–ª–∏ --charts –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ rankings")
        return
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    datasets = config.get('datasets', {})
    
    print(f"–î–∞—Ç–∞—Å–µ—Ç–æ–≤: {len(datasets)}\n")
    
    all_results = collect_all_results(args.results_dir, args.data_root, datasets, args.python)
    
    for dataset_name in datasets.keys():
        results = all_results.get(dataset_name, {})
        if results:
            print(f"\n{'='*60}")
            print(f"{dataset_name}: {len(results)} –º–æ–¥–µ–ª–µ–π")
            print(f"{'='*60}")
            create_ranking_table(dataset_name, results, args.output_dir)
    
    print(f"\n{'='*60}")
    print(f"–ì–æ—Ç–æ–≤–æ! –í—Å–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}")
    print(f"{'='*60}")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º README (–≤–∫–ª—é—á–∞—è –≥—Ä–∞—Ñ–∏–∫–∏) –µ—Å–ª–∏ –Ω–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ
    if not args.no_readme:
        print(f"\n{'='*60}")
        print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è README –∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
        print(f"{'='*60}")
        generate_readme(args.output_dir, config, generate_charts=not args.no_charts)
    elif not args.no_charts:
        # –ï—Å–ª–∏ README –æ—Ç–∫–ª—é—á–µ–Ω, –Ω–æ –≥—Ä–∞—Ñ–∏–∫–∏ –Ω—É–∂–Ω—ã
        print(f"\n{'='*60}")
        print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
        print(f"{'='*60}")
        plot_radar_charts(args.output_dir)


if __name__ == "__main__":
    main()
